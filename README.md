# Search Engine Preprocessing Pipeline

This repository contains the template and working code for a search engine application built as part of an NLP assignment.

## Model Architecture
![Model Architecture](model_flow_nlp.png)

---

## ğŸ“ Project Structure

```plaintext
.
â”œâ”€â”€ MM19B046-MM19B022-NLP-1.pdf              # Assignment report
â”œâ”€â”€ Project2_LSA+W2V.ipynb                   # Word2Vec + LSA model notebook
â”œâ”€â”€ Project2_LSA+W2V_FINAL.pdf               # Model code document
â”œâ”€â”€ Project2_LSA+bert.ipynb                  # BERT-based model notebook
â”œâ”€â”€ model_flow_nlp.png                       # System architecture diagram
â”œâ”€â”€ README.md                                # Project overview
â””â”€â”€ code/
    â”œâ”€â”€ main.py                              # Main driver script (DO NOT modify)
    â”œâ”€â”€ util.py                              # Utility functions (customizable)
    â”œâ”€â”€ inflectionReduction.py               # Lemmatization/stemming logic
    â”œâ”€â”€ sentenceSegmentation.py              # Sentence segmentation logic
    â”œâ”€â”€ stopwordRemoval.py                   # Stop word removal logic
    â”œâ”€â”€ tokenization.py                      # Tokenization logic
    â”œâ”€â”€ cranfield/                           # Cranfield dataset
    â”‚   â”œâ”€â”€ cran_docs.json
    â”‚   â”œâ”€â”€ cran_qrels.json
    â”‚   â”œâ”€â”€ cran_queries.json
    â”‚   â””â”€â”€ README.txt
    â”œâ”€â”€ output/                              # Outputs after each stage
    â”‚   â”œâ”€â”€ outputsegmented_docs.txt
    â”‚   â”œâ”€â”€ outputsegmented_queries.txt
    â”‚   â”œâ”€â”€ outputtokenized_docs.txt
    â”‚   â”œâ”€â”€ outputtokenized_queries.txt
    â”‚   â”œâ”€â”€ outputstopword_removed_docs.txt
    â”‚   â”œâ”€â”€ outputstopword_removed_queries.txt
    â”‚   â”œâ”€â”€ outputreduced_docs.txt
    â”‚   â””â”€â”€ outputreduced_queries.txt
    â””â”€â”€ __pycache__/                         # Cached Python files
```
---
## ğŸš€ How to Run
Use the main.py script to run the full preprocessing pipeline.

### Basic Usage:
```
python main.py [-custom] [-dataset DATASET_FOLDER] [-out_folder OUTPUT_FOLDER]
               [-segmenter SEGMENTER_TYPE (naive|punkt)] 
               [-tokenizer TOKENIZER_TYPE (naive|ptb)]

```

### Example usage 
```
python main.py -custom

```

Read the final report for additional details 
